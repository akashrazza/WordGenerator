{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashrazza/WordGenerator/blob/main/assiment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziSU-CdqqwQr",
        "outputId": "311a08c1-6ad3-46fa-c518-4999923f34b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gensim version: \t4.3.2\n",
            "TensorFlow version: \t2.14.0\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import tensorflow as tf\n",
        "\n",
        "print('gensim version: \\t%s' % gensim.__version__)\n",
        "print('TensorFlow version: \\t%s' % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoTg2-DzqwQu"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fo65dZSEqwQv"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# For displaying gensim logs\n",
        "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "# Directory with raw txt-files\n",
        "TEXT_DIR  = '/'\n",
        "\n",
        "# Directory for saving checkpoint and metadata\n",
        "MODEL_DIR = '/'\n",
        "\n",
        "# Word2vec\n",
        "EMBEDDING_SIZE = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEVa7e66qwQw"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNQ6s8eyqwQw",
        "outputId": "3290462c-e8f3-4c9c-a065-5305cf358aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 1\n"
          ]
        }
      ],
      "source": [
        "import os, re, string\n",
        "\n",
        "\n",
        "def clean_doc(doc):\n",
        "    \"\"\"\n",
        "    Cleaning a document by several methods\n",
        "    \"\"\"\n",
        "    # Lowercase\n",
        "    doc = doc.lower()\n",
        "    # Remove numbers\n",
        "    doc = re.sub(r\"[0-9]+\", \"\", doc)\n",
        "    # Split in tokens\n",
        "    tokens = doc.split()\n",
        "    # Remove punctuation\n",
        "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
        "    # Tokens with less then two characters will be ignored\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# f=open(\"w2v.txt\",\"r\")\n",
        "# print(f.read())\n",
        "def read_files(path):\n",
        "    \"\"\"\n",
        "    Read in text files\n",
        "    \"\"\"\n",
        "    documents = list()\n",
        "    tokenize  = lambda x: gensim.utils.simple_preprocess(x)\n",
        "\n",
        "    # Read in all files in directory\n",
        "#     if os.path.isdir(path):\n",
        "#         for filename in os.listdir(path):\n",
        "#             with open(\"w2v.txt\", encoding='utf-8') as f:\n",
        "    f=open(\"w2v.txt\",\"r\")\n",
        "    doc = f.read()\n",
        "    doc = clean_doc(doc)\n",
        "    documents.append(tokenize(doc))\n",
        "    return documents\n",
        "\n",
        "docs = read_files(TEXT_DIR)\n",
        "print('Number of documents: %i' % len(docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNUP2JBRqwQx"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "RJj2Sr4bqwQx"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(docs, min_count=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCr-0uRQqwQy"
      },
      "source": [
        "## Saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rlIT6ZPDqwQy"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "model.save(os.path.join(MODEL_DIR,'word2vec'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzybY5jrqwQz"
      },
      "source": [
        "## Creating checkpoint and metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-dqB57eqwQz",
        "outputId": "c114b76d-f3ed-42da-82ac-6cb8c51805a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of weights: (263, 100)\n",
            "Vocabulary size: 263\n",
            "Embedding size: 100\n"
          ]
        }
      ],
      "source": [
        "from tensorboard.plugins import projector\n",
        "\n",
        "weights     = model.wv.vectors\n",
        "index_words = model.wv.index_to_key\n",
        "\n",
        "vocab_size    = weights.shape[0]\n",
        "embedding_dim = weights.shape[1]\n",
        "\n",
        "print('Shape of weights:', weights.shape)\n",
        "print('Vocabulary size: %i' % vocab_size)\n",
        "print('Embedding size: %i'  % embedding_dim)\n",
        "\n",
        "with open(os.path.join(MODEL_DIR,'metadata.tsv'), 'w') as f:\n",
        "    f.writelines(\"\\n\".join(index_words))\n",
        "\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = 'embeddings'\n",
        "embedding.metadata_path = './metadata.tsv'\n",
        "projector.visualize_embeddings(MODEL_DIR, config)\n",
        "\n",
        "tensor_embeddings = tf.Variable(model.wv.vectors, name='embeddings')\n",
        "\n",
        "checkpoint = tf.compat.v1.train.Saver([tensor_embeddings])\n",
        "checkpoint_path = checkpoint.save(sess=None, global_step=None, save_path=os.path.join(MODEL_DIR, \"model.ckpt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ufKWp57qwQz"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzJFIzcZqwQ0",
        "outputId": "5dc0381a-507c-422c-f742-2bfcbe5793cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 0.2520006000995636),\n",
              " ('some', 0.24385978281497955),\n",
              " ('lle', 0.21587562561035156),\n",
              " ('it', 0.21149316430091858),\n",
              " ('firth', 0.21078528463840485),\n",
              " ('biovec', 0.20363563299179077),\n",
              " ('number', 0.19869697093963623),\n",
              " ('gradually', 0.1941036432981491),\n",
              " ('reducing', 0.19298714399337769),\n",
              " ('representations', 0.18559524416923523)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['bioinformatics'], topn=10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}